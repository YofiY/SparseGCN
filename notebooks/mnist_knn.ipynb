{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST KNN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import graphlearning as gl\n",
    "import numpy as np\n",
    "import pygsp\n",
    "import rustworkx as rwx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.logging import log\n",
    "from torch_geometric.nn import GCNConv\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src import get_num_edges_from_adj_matrix, generate_train_and_test_mask, GCN, eval_model, spectral_sparsify, mb_sparsify, thresh_sparsify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking: mnist dataset\n",
      "    > 784 features\n",
      "    > 10 classes\n"
     ]
    }
   ],
   "source": [
    "ds_name = \"mnist\"\n",
    "print(f\"Benchmarking: {ds_name} dataset\")\n",
    "\n",
    "num_features = 784\n",
    "num_classes = 10\n",
    "print(f\"    > {num_features} features\")\n",
    "print(f\"    > {num_classes} classes\")\n",
    "\n",
    "# Loading the dataset :\n",
    "source_data, labels = gl.datasets.load(\"mnist\")\n",
    "\n",
    "N = source_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    > Running on a subsample of 2000 Nodes\n"
     ]
    }
   ],
   "source": [
    "subsample_size = 2000\n",
    "N = subsample_size\n",
    "print(f\"    > Running on a subsample of {subsample_size} Nodes\")\n",
    "indices = np.arange(0, source_data.shape[0], 1, dtype=int)\n",
    "np.random.shuffle(indices)\n",
    "chosen_indices = indices[:subsample_size]\n",
    "source_data = source_data[chosen_indices, :]\n",
    "labels = labels[chosen_indices]\n",
    "\n",
    "K_range = [i for i in range(10,101,10)]\n",
    "N_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats for the full graph\n",
    "full_graph_training_time = np.zeros(len(K_range))\n",
    "full_graph_training_time_per_epoch = np.zeros(len(K_range))\n",
    "full_graph_accuracies = np.zeros(((len(K_range), N_EPOCHS)))\n",
    "full_graph_best_accuracies = np.zeros(len(K_range))\n",
    "full_graph_num_edges = np.zeros(len(K_range))\n",
    "full_graph_sparsification_time = np.zeros(len(K_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contructing the knn weightmatrix for k = 10...\n",
      "done in 0.8230\n",
      "the graph has 14581 edges\n",
      "Epoch: 001, Loss: 2.3442, Train: 0.1910, Test: 0.1820\n",
      "Epoch: 010, Loss: 0.8910, Train: 0.8140, Test: 0.8200\n",
      "Epoch: 020, Loss: 0.5381, Train: 0.8730, Test: 0.8700\n",
      "Epoch: 030, Loss: 0.4452, Train: 0.8940, Test: 0.8890\n",
      "Epoch: 040, Loss: 0.3933, Train: 0.9120, Test: 0.9020\n",
      "Epoch: 050, Loss: 0.3819, Train: 0.9150, Test: 0.9030\n",
      "Epoch: 060, Loss: 0.3372, Train: 0.9180, Test: 0.9010\n",
      "Epoch: 070, Loss: 0.3061, Train: 0.9250, Test: 0.9030\n",
      "Epoch: 080, Loss: 0.2942, Train: 0.9310, Test: 0.9060\n",
      "Epoch: 090, Loss: 0.2653, Train: 0.9380, Test: 0.9140\n",
      "Epoch: 100, Loss: 0.2951, Train: 0.9350, Test: 0.9090\n",
      "contructing the knn weightmatrix for k = 20...\n",
      "done in 0.8006\n",
      "the graph has 28776 edges\n",
      "Epoch: 001, Loss: 2.3656, Train: 0.2220, Test: 0.2010\n",
      "Epoch: 010, Loss: 0.9416, Train: 0.7930, Test: 0.8060\n",
      "Epoch: 020, Loss: 0.6100, Train: 0.8390, Test: 0.8470\n",
      "Epoch: 030, Loss: 0.5051, Train: 0.8750, Test: 0.8720\n",
      "Epoch: 040, Loss: 0.4453, Train: 0.8990, Test: 0.8840\n",
      "Epoch: 050, Loss: 0.4050, Train: 0.8930, Test: 0.8890\n",
      "Epoch: 060, Loss: 0.3879, Train: 0.9020, Test: 0.8910\n",
      "Epoch: 070, Loss: 0.3534, Train: 0.9030, Test: 0.8900\n",
      "Epoch: 080, Loss: 0.3596, Train: 0.9040, Test: 0.8950\n",
      "Epoch: 090, Loss: 0.3681, Train: 0.9040, Test: 0.8950\n",
      "Epoch: 100, Loss: 0.3616, Train: 0.9050, Test: 0.8910\n",
      "contructing the knn weightmatrix for k = 30...\n",
      "done in 0.8168\n",
      "the graph has 42964 edges\n",
      "Epoch: 001, Loss: 2.4172, Train: 0.2340, Test: 0.1980\n",
      "Epoch: 010, Loss: 1.1839, Train: 0.6640, Test: 0.6540\n",
      "Epoch: 020, Loss: 0.7577, Train: 0.7660, Test: 0.7750\n",
      "Epoch: 030, Loss: 0.6513, Train: 0.8100, Test: 0.8180\n",
      "Epoch: 040, Loss: 0.5779, Train: 0.8200, Test: 0.8410\n",
      "Epoch: 050, Loss: 0.5448, Train: 0.8260, Test: 0.8440\n",
      "Epoch: 060, Loss: 0.4838, Train: 0.8500, Test: 0.8520\n",
      "Epoch: 070, Loss: 0.4739, Train: 0.8540, Test: 0.8660\n",
      "Epoch: 080, Loss: 0.4756, Train: 0.8680, Test: 0.8760\n",
      "Epoch: 090, Loss: 0.4549, Train: 0.8730, Test: 0.8810\n",
      "Epoch: 100, Loss: 0.4167, Train: 0.8750, Test: 0.8660\n",
      "contructing the knn weightmatrix for k = 40...\n",
      "done in 0.8605\n",
      "the graph has 57074 edges\n",
      "Epoch: 001, Loss: 2.3314, Train: 0.3240, Test: 0.2960\n",
      "Epoch: 010, Loss: 1.1878, Train: 0.7220, Test: 0.6840\n",
      "Epoch: 020, Loss: 0.7223, Train: 0.7790, Test: 0.7550\n",
      "Epoch: 030, Loss: 0.6030, Train: 0.8160, Test: 0.8060\n",
      "Epoch: 040, Loss: 0.5447, Train: 0.8490, Test: 0.8240\n",
      "Epoch: 050, Loss: 0.4863, Train: 0.8630, Test: 0.8300\n",
      "Epoch: 060, Loss: 0.4529, Train: 0.8700, Test: 0.8420\n",
      "Epoch: 070, Loss: 0.4303, Train: 0.8730, Test: 0.8350\n",
      "Epoch: 080, Loss: 0.4253, Train: 0.8710, Test: 0.8390\n",
      "Epoch: 090, Loss: 0.4128, Train: 0.8800, Test: 0.8450\n",
      "Epoch: 100, Loss: 0.4175, Train: 0.8860, Test: 0.8510\n",
      "contructing the knn weightmatrix for k = 50...\n",
      "done in 0.9589\n",
      "the graph has 71058 edges\n",
      "Epoch: 001, Loss: 2.3491, Train: 0.2910, Test: 0.2850\n",
      "Epoch: 010, Loss: 1.2727, Train: 0.6730, Test: 0.6670\n",
      "Epoch: 020, Loss: 0.8618, Train: 0.7510, Test: 0.7580\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m\n\u001b[1;32m     19\u001b[0m full_graph_model \u001b[38;5;241m=\u001b[39m GCN(num_features, \u001b[38;5;241m16\u001b[39m, num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m full_graph_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam([\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mdict\u001b[39m(params\u001b[38;5;241m=\u001b[39mfull_graph_model\u001b[38;5;241m.\u001b[39mconv1\u001b[38;5;241m.\u001b[39mparameters(), weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m),\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mdict\u001b[39m(params\u001b[38;5;241m=\u001b[39mfull_graph_model\u001b[38;5;241m.\u001b[39mconv2\u001b[38;5;241m.\u001b[39mparameters(), weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m ], lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)  \u001b[38;5;66;03m# Only perform weight-decay on first convolution.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m best_val_acc, accs, median_time_per_epoch, overall_time \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_graph_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mfull_graph_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mtest_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mfull_graph_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EPFL/BA6/Bachelor-Thesis/SparseGNN/src/evaluate.py:26\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, data, train_mask, test_mask, optimizer, N_EPOCHS)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, N_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     25\u001b[0m     epoch_train_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     train_acc, test_acc \u001b[38;5;241m=\u001b[39m test(model, data, train_mask, test_mask)\n\u001b[1;32m     28\u001b[0m     best_val_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(train_acc, best_val_acc)\n",
      "File \u001b[0;32m~/EPFL/BA6/Bachelor-Thesis/SparseGNN/src/train.py:7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data, train_mask)\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr)\n\u001b[0;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(out[train_mask], \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m[train_mask])\n\u001b[1;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch_geometric/data/data.py:980\u001b[0m, in \u001b[0;36mData.y\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;129m@edge_attr\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21medge_attr\u001b[39m(\u001b[38;5;28mself\u001b[39m, edge_attr: Optional[Tensor]):\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m edge_attr\n\u001b[0;32m--> 980\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21my\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[Tensor, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;129m@y\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21my\u001b[39m(\u001b[38;5;28mself\u001b[39m, y: Optional[Tensor]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k_idx, k in enumerate(K_range):\n",
    "    print(f\"contructing the knn weightmatrix for k = {k}...\")\n",
    "    start_knn_weight_matrix_time = time.time()\n",
    "    knn_weight_matrix = gl.weightmatrix.knn(source_data, k=k)\n",
    "    knn_weight_matrix_time = time.time() - start_knn_weight_matrix_time\n",
    "    full_graph_sparsification_time[k_idx] = knn_weight_matrix_time \n",
    "    print(f\"done in {knn_weight_matrix_time:.4f}\")\n",
    "    print(f\"the graph has {get_num_edges_from_adj_matrix(knn_weight_matrix.toarray())} edges\")       \n",
    "    full_graph_num_edges[k_idx] = get_num_edges_from_adj_matrix(knn_weight_matrix.toarray()) \n",
    "    train_mask, test_mask = generate_train_and_test_mask(N)\n",
    "    \n",
    "    full_graph_x = torch.tensor(source_data, dtype=torch.float)\n",
    "    full_graph_y = torch.tensor(labels, dtype=torch.long)\n",
    "    full_graph_edge_index = (\n",
    "        torch.tensor(knn_weight_matrix.toarray()).nonzero().t().contiguous()\n",
    "    )\n",
    "    full_graph_data = Data(x=full_graph_x, edge_index=full_graph_edge_index, y=full_graph_y).to(device)\n",
    "    # NOTE: des num_nodes update after having cut the dataset to get the subsample ?\n",
    "    full_graph_model = GCN(num_features, 16, num_classes).to(device)\n",
    "    \n",
    "    full_graph_optimizer = torch.optim.Adam([\n",
    "        dict(params=full_graph_model.conv1.parameters(), weight_decay=5e-4),\n",
    "        dict(params=full_graph_model.conv2.parameters(), weight_decay=0)\n",
    "    ], lr=0.01)  # Only perform weight-decay on first convolution.\n",
    "    \n",
    "    best_val_acc, accs, median_time_per_epoch, overall_time = eval_model(full_graph_model, \n",
    "                                                                            full_graph_data,\n",
    "                                                                            train_mask,\n",
    "                                                                            test_mask, \n",
    "                                                                            full_graph_optimizer,\n",
    "                                                                            N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Sparsified Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats for the spectral sparsification\n",
    "spectral_training_time = np.zeros(len(K_range))\n",
    "spectral_graph_training_time_per_epoch = np.zeros(len(K_range))\n",
    "spectral_accuracies = np.zeros(((len(K_range), N_EPOCHS))) \n",
    "spectral_best_accuracies = np.zeros(len(K_range))\n",
    "spectral_num_edges = np.zeros(len(K_range))\n",
    "spectral_sparsification_time = np.zeros(len(K_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing the spectral sparisfied graph using effective resistance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/t1p1zlw56kx34l_phf3ncrg40000gn/T/ipykernel_21611/3197016560.py:5: RuntimeWarning: divide by zero encountered in divide\n",
      "  spectral_sparse_knn_weight_matrix = spectral_sparsify(np.nan_to_num((1/knn_weight_matrix.todense())-1, posinf = 0, neginf = 0, nan = 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.2693s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 10888.0, with K = 10 --------------------------\n",
      "Epoch: 001, Loss: 2.3533, Train: 0.4700, Test: 0.4520\n",
      "Epoch: 010, Loss: 1.0550, Train: 0.7660, Test: 0.7550\n",
      "Epoch: 020, Loss: 0.6605, Train: 0.8590, Test: 0.8350\n",
      "Epoch: 030, Loss: 0.5671, Train: 0.8830, Test: 0.8530\n",
      "Epoch: 040, Loss: 0.4842, Train: 0.8930, Test: 0.8600\n",
      "Epoch: 050, Loss: 0.4316, Train: 0.9090, Test: 0.8700\n",
      "Epoch: 060, Loss: 0.3904, Train: 0.9100, Test: 0.8830\n",
      "Epoch: 070, Loss: 0.4000, Train: 0.9130, Test: 0.8760\n",
      "Epoch: 080, Loss: 0.3812, Train: 0.9180, Test: 0.8860\n",
      "Epoch: 090, Loss: 0.3292, Train: 0.9180, Test: 0.8850\n",
      "Epoch: 100, Loss: 0.3344, Train: 0.9190, Test: 0.8820\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 2.7967s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 15446.0, with K = 20 --------------------------\n",
      "Epoch: 001, Loss: 2.2930, Train: 0.2920, Test: 0.2800\n",
      "Epoch: 010, Loss: 0.9719, Train: 0.7920, Test: 0.7410\n",
      "Epoch: 020, Loss: 0.6599, Train: 0.8410, Test: 0.7910\n",
      "Epoch: 030, Loss: 0.5554, Train: 0.8520, Test: 0.8100\n",
      "Epoch: 040, Loss: 0.5057, Train: 0.8570, Test: 0.8320\n",
      "Epoch: 050, Loss: 0.4851, Train: 0.8690, Test: 0.8440\n",
      "Epoch: 060, Loss: 0.4768, Train: 0.8710, Test: 0.8510\n",
      "Epoch: 070, Loss: 0.4444, Train: 0.8770, Test: 0.8550\n",
      "Epoch: 080, Loss: 0.4455, Train: 0.8820, Test: 0.8600\n",
      "Epoch: 090, Loss: 0.4262, Train: 0.8790, Test: 0.8580\n",
      "Epoch: 100, Loss: 0.4250, Train: 0.8840, Test: 0.8610\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 2.7857s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 17781.0, with K = 30 --------------------------\n",
      "Epoch: 001, Loss: 2.3191, Train: 0.1770, Test: 0.1810\n",
      "Epoch: 010, Loss: 1.1251, Train: 0.7150, Test: 0.7160\n",
      "Epoch: 020, Loss: 0.8478, Train: 0.7730, Test: 0.7850\n",
      "Epoch: 030, Loss: 0.7445, Train: 0.7950, Test: 0.7950\n",
      "Epoch: 040, Loss: 0.6697, Train: 0.8090, Test: 0.8070\n",
      "Epoch: 050, Loss: 0.6417, Train: 0.8200, Test: 0.8120\n",
      "Epoch: 060, Loss: 0.5982, Train: 0.8210, Test: 0.8180\n",
      "Epoch: 070, Loss: 0.5756, Train: 0.8260, Test: 0.8210\n",
      "Epoch: 080, Loss: 0.5612, Train: 0.8410, Test: 0.8260\n",
      "Epoch: 090, Loss: 0.5400, Train: 0.8540, Test: 0.8330\n",
      "Epoch: 100, Loss: 0.5637, Train: 0.8500, Test: 0.8350\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 3.4426s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 19190.0, with K = 40 --------------------------\n",
      "Epoch: 001, Loss: 2.3839, Train: 0.0970, Test: 0.1030\n",
      "Epoch: 010, Loss: 1.8555, Train: 0.4870, Test: 0.5090\n",
      "Epoch: 020, Loss: 1.3467, Train: 0.6070, Test: 0.6220\n",
      "Epoch: 030, Loss: 1.0550, Train: 0.6890, Test: 0.6800\n",
      "Epoch: 040, Loss: 0.9341, Train: 0.7320, Test: 0.7310\n",
      "Epoch: 050, Loss: 0.8457, Train: 0.7510, Test: 0.7550\n",
      "Epoch: 060, Loss: 0.8215, Train: 0.7670, Test: 0.7640\n",
      "Epoch: 070, Loss: 0.7627, Train: 0.7850, Test: 0.7800\n",
      "Epoch: 080, Loss: 0.7736, Train: 0.7880, Test: 0.7910\n",
      "Epoch: 090, Loss: 0.7504, Train: 0.7990, Test: 0.7920\n",
      "Epoch: 100, Loss: 0.7064, Train: 0.7990, Test: 0.7930\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 3.9277s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 20151.0, with K = 50 --------------------------\n",
      "Epoch: 001, Loss: 2.3030, Train: 0.2190, Test: 0.2080\n",
      "Epoch: 010, Loss: 1.6387, Train: 0.4290, Test: 0.4070\n",
      "Epoch: 020, Loss: 1.2365, Train: 0.6320, Test: 0.5990\n",
      "Epoch: 030, Loss: 0.9889, Train: 0.7290, Test: 0.6990\n",
      "Epoch: 040, Loss: 0.9062, Train: 0.7550, Test: 0.7340\n",
      "Epoch: 050, Loss: 0.8182, Train: 0.7820, Test: 0.7680\n",
      "Epoch: 060, Loss: 0.7615, Train: 0.8010, Test: 0.7830\n",
      "Epoch: 070, Loss: 0.7643, Train: 0.8040, Test: 0.8030\n",
      "Epoch: 080, Loss: 0.7386, Train: 0.8080, Test: 0.7910\n",
      "Epoch: 090, Loss: 0.6998, Train: 0.8100, Test: 0.7990\n",
      "Epoch: 100, Loss: 0.7270, Train: 0.8130, Test: 0.8010\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 4.1730s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 20888.0, with K = 60 --------------------------\n",
      "Epoch: 001, Loss: 2.3393, Train: 0.2810, Test: 0.2570\n",
      "Epoch: 010, Loss: 1.5535, Train: 0.4960, Test: 0.4660\n",
      "Epoch: 020, Loss: 1.1289, Train: 0.6660, Test: 0.6420\n",
      "Epoch: 030, Loss: 0.9906, Train: 0.7310, Test: 0.6910\n",
      "Epoch: 040, Loss: 0.8848, Train: 0.7620, Test: 0.7150\n",
      "Epoch: 050, Loss: 0.8446, Train: 0.7750, Test: 0.7450\n",
      "Epoch: 060, Loss: 0.8219, Train: 0.7710, Test: 0.7390\n",
      "Epoch: 070, Loss: 0.7674, Train: 0.7920, Test: 0.7490\n",
      "Epoch: 080, Loss: 0.7468, Train: 0.7960, Test: 0.7540\n",
      "Epoch: 090, Loss: 0.7218, Train: 0.8030, Test: 0.7530\n",
      "Epoch: 100, Loss: 0.6993, Train: 0.8130, Test: 0.7730\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 4.1681s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 21305.0, with K = 70 --------------------------\n",
      "Epoch: 001, Loss: 2.3247, Train: 0.1680, Test: 0.1540\n",
      "Epoch: 010, Loss: 1.3731, Train: 0.6230, Test: 0.6260\n",
      "Epoch: 020, Loss: 1.0009, Train: 0.7160, Test: 0.7000\n",
      "Epoch: 030, Loss: 0.9037, Train: 0.7540, Test: 0.7200\n",
      "Epoch: 040, Loss: 0.8570, Train: 0.7690, Test: 0.7390\n",
      "Epoch: 050, Loss: 0.8169, Train: 0.7740, Test: 0.7580\n",
      "Epoch: 060, Loss: 0.7736, Train: 0.7630, Test: 0.7500\n",
      "Epoch: 070, Loss: 0.7226, Train: 0.7800, Test: 0.7630\n",
      "Epoch: 080, Loss: 0.7737, Train: 0.7830, Test: 0.7640\n",
      "Epoch: 090, Loss: 0.7760, Train: 0.7970, Test: 0.7750\n",
      "Epoch: 100, Loss: 0.7432, Train: 0.7990, Test: 0.7850\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 4.5432s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 21761.0, with K = 80 --------------------------\n",
      "Epoch: 001, Loss: 2.3816, Train: 0.2020, Test: 0.1940\n",
      "Epoch: 010, Loss: 1.8375, Train: 0.4100, Test: 0.4070\n",
      "Epoch: 020, Loss: 1.4312, Train: 0.5290, Test: 0.5250\n",
      "Epoch: 030, Loss: 1.2604, Train: 0.6310, Test: 0.6160\n",
      "Epoch: 040, Loss: 1.1262, Train: 0.6800, Test: 0.6510\n",
      "Epoch: 050, Loss: 1.0527, Train: 0.6940, Test: 0.6800\n",
      "Epoch: 060, Loss: 0.9884, Train: 0.7120, Test: 0.6980\n",
      "Epoch: 070, Loss: 0.9643, Train: 0.7240, Test: 0.7080\n",
      "Epoch: 080, Loss: 0.9574, Train: 0.7320, Test: 0.7190\n",
      "Epoch: 090, Loss: 0.9420, Train: 0.7360, Test: 0.7260\n",
      "Epoch: 100, Loss: 0.9552, Train: 0.7200, Test: 0.7140\n",
      "constructing the spectral sparisfied graph using effective resistance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yofi/miniconda3/lib/python3.11/site-packages/pygsp/reduction.py:118: RuntimeWarning: divide by zero encountered in divide\n",
      "  per_spin_weights = weights / (q * Pe)\n",
      "/Users/yofi/miniconda3/lib/python3.11/site-packages/pygsp/reduction.py:122: RuntimeWarning: invalid value encountered in multiply\n",
      "  new_weights = counts * per_spin_weights\n",
      "2024-06-04 15:13:11,293:[WARNING](pygsp.graphs.graph.check_weights): There is a NaN value in the weight matrix!\n",
      "2024-06-04 15:13:12,121:[WARNING](pygsp.graphs.graph.check_weights): There is a NaN value in the weight matrix!\n",
      "2024-06-04 15:13:12,363:[WARNING](pygsp.graphs.graph.check_weights): There is a NaN value in the weight matrix!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.9582s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 27080.0, with K = 90 --------------------------\n",
      "Epoch: 001, Loss: 2.2862, Train: 0.1760, Test: 0.1640\n",
      "Epoch: 010, Loss: 1.5151, Train: 0.5790, Test: 0.5850\n",
      "Epoch: 020, Loss: 1.1616, Train: 0.6400, Test: 0.6480\n",
      "Epoch: 030, Loss: 1.0027, Train: 0.7030, Test: 0.7000\n",
      "Epoch: 040, Loss: 0.9559, Train: 0.7100, Test: 0.7180\n",
      "Epoch: 050, Loss: 0.9094, Train: 0.7190, Test: 0.7160\n",
      "Epoch: 060, Loss: 0.8864, Train: 0.7270, Test: 0.7340\n",
      "Epoch: 070, Loss: 0.8291, Train: 0.7470, Test: 0.7460\n",
      "Epoch: 080, Loss: 0.8173, Train: 0.7580, Test: 0.7500\n",
      "Epoch: 090, Loss: 0.8132, Train: 0.7630, Test: 0.7580\n",
      "Epoch: 100, Loss: 0.7672, Train: 0.7770, Test: 0.7520\n",
      "constructing the spectral sparisfied graph using effective resistance\n",
      "done in 4.8560s\n",
      "-------------------------- Running the model Spectral sparsified |E| = 22437.0, with K = 100 --------------------------\n",
      "Epoch: 001, Loss: 2.3242, Train: 0.1440, Test: 0.1270\n",
      "Epoch: 010, Loss: 1.6229, Train: 0.5120, Test: 0.5050\n",
      "Epoch: 020, Loss: 1.2816, Train: 0.6150, Test: 0.6130\n",
      "Epoch: 030, Loss: 1.1471, Train: 0.6600, Test: 0.6200\n",
      "Epoch: 040, Loss: 1.0430, Train: 0.6980, Test: 0.6730\n",
      "Epoch: 050, Loss: 1.0100, Train: 0.7260, Test: 0.6890\n",
      "Epoch: 060, Loss: 0.9503, Train: 0.7300, Test: 0.6770\n",
      "Epoch: 070, Loss: 0.9220, Train: 0.7550, Test: 0.7050\n",
      "Epoch: 080, Loss: 0.8830, Train: 0.7540, Test: 0.7060\n",
      "Epoch: 090, Loss: 0.8681, Train: 0.7600, Test: 0.7040\n",
      "Epoch: 100, Loss: 0.8399, Train: 0.7650, Test: 0.7130\n"
     ]
    }
   ],
   "source": [
    "for k_idx, k in enumerate(K_range):\n",
    "    print(f\"constructing the spectral sparisfied graph using effective resistance\")\n",
    "    knn_weight_matrix = gl.weightmatrix.knn(source_data, k=k)\n",
    "    start_spectral_sparsify = time.time() \n",
    "    spectral_sparse_knn_weight_matrix = spectral_sparsify(np.nan_to_num((1/knn_weight_matrix.todense())-1, posinf = 0, neginf = 0, nan = 0))\n",
    "    spectral_sparsify_time = time.time() - start_spectral_sparsify\n",
    "    print(f\"done in {spectral_sparsify_time:.4f}s\")\n",
    "    spectral_sparsification_time[k_idx] = spectral_sparsify_time\n",
    "    spectral_num_edges[k_idx] = get_num_edges_from_adj_matrix(spectral_sparse_knn_weight_matrix.toarray())\n",
    "    train_mask, test_mask = generate_train_and_test_mask(N)\n",
    "\n",
    "        \n",
    "    print(f'-------------------------- Running the model Spectral sparsified |E| = {spectral_num_edges[k_idx]}, with K = {k} --------------------------')\n",
    "    # Running the model on the spectral sparsified graph\n",
    "    spectral_x = torch.tensor(source_data, dtype=torch.float)\n",
    "    spectral_y = torch.tensor(labels, dtype=torch.long)\n",
    "    spectral_edge_index = (\n",
    "        torch.tensor(spectral_sparse_knn_weight_matrix.toarray()).nonzero().t().contiguous()\n",
    "    )\n",
    "    spectral_data = Data(x=spectral_x, edge_index=spectral_edge_index, y=spectral_y).to(device)\n",
    "    # NOTE: des num_nodes update after having cut the dataset to get the subsample ?\n",
    "    spectral_model = GCN(num_features, 16, num_classes).to(device)\n",
    "\n",
    "    spectral_optimizer = torch.optim.Adam([\n",
    "        dict(params=spectral_model.conv1.parameters(), weight_decay=5e-4),\n",
    "        dict(params=spectral_model.conv2.parameters(), weight_decay=0)\n",
    "    ], lr=0.01)  # Only perform weight-decay on first convolution.\n",
    "\n",
    "    best_val_acc, accs, median_time_per_epoch, overall_time = eval_model(spectral_model, \n",
    "                                                                            spectral_data,\n",
    "                                                                            train_mask,\n",
    "                                                                            test_mask, \n",
    "                                                                            spectral_optimizer,\n",
    "                                                                            N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats for the metric backbone\n",
    "mb_training_time = np.zeros(len(K_range))\n",
    "mb_graph_training_time_per_epoch = np.zeros(len(K_range))\n",
    "mb_accuracies = np.zeros(((len(K_range), N_EPOCHS)))\n",
    "mb_best_accuracies = np.zeros(len(K_range))\n",
    "mb_num_edges = np.zeros(len(K_range))\n",
    "mb_sparsification_time = np.zeros(len(K_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing the metric backbone graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/t1p1zlw56kx34l_phf3ncrg40000gn/T/ipykernel_22586/306633343.py:5: RuntimeWarning: divide by zero encountered in divide\n",
      "  mb_sparse_knn_weight_matrix = mb_sparsify(np.nan_to_num((1/knn_weight_matrix.todense())-1, posinf = 0, neginf = 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.2729s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 7514.0, with K = 10 --------------------------\n",
      "Epoch: 001, Loss: 2.3656, Train: 0.2930, Test: 0.3120\n",
      "Epoch: 010, Loss: 1.0664, Train: 0.7350, Test: 0.7220\n",
      "Epoch: 020, Loss: 0.7241, Train: 0.8180, Test: 0.8170\n",
      "Epoch: 030, Loss: 0.6069, Train: 0.8540, Test: 0.8460\n",
      "Epoch: 040, Loss: 0.5215, Train: 0.8770, Test: 0.8650\n",
      "Epoch: 050, Loss: 0.4704, Train: 0.8890, Test: 0.8780\n",
      "Epoch: 060, Loss: 0.4510, Train: 0.8920, Test: 0.8820\n",
      "Epoch: 070, Loss: 0.4428, Train: 0.9020, Test: 0.8820\n",
      "Epoch: 080, Loss: 0.4155, Train: 0.9050, Test: 0.8800\n",
      "Epoch: 090, Loss: 0.4146, Train: 0.9080, Test: 0.8920\n",
      "Epoch: 100, Loss: 0.4145, Train: 0.9110, Test: 0.8880\n",
      "median time per epoch: 0.0146s\n",
      "constructing the metric backbone graph\n",
      "done in 0.4091s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 9903.0, with K = 20 --------------------------\n",
      "Epoch: 001, Loss: 2.4117, Train: 0.2880, Test: 0.3010\n",
      "Epoch: 010, Loss: 1.3815, Train: 0.6520, Test: 0.6350\n",
      "Epoch: 020, Loss: 0.9424, Train: 0.7940, Test: 0.7650\n",
      "Epoch: 030, Loss: 0.7317, Train: 0.8240, Test: 0.8040\n",
      "Epoch: 040, Loss: 0.6460, Train: 0.8520, Test: 0.8270\n",
      "Epoch: 050, Loss: 0.5592, Train: 0.8640, Test: 0.8410\n",
      "Epoch: 060, Loss: 0.5440, Train: 0.8720, Test: 0.8490\n",
      "Epoch: 070, Loss: 0.5278, Train: 0.8780, Test: 0.8590\n",
      "Epoch: 080, Loss: 0.5049, Train: 0.8900, Test: 0.8520\n",
      "Epoch: 090, Loss: 0.4486, Train: 0.8960, Test: 0.8790\n",
      "Epoch: 100, Loss: 0.4780, Train: 0.9010, Test: 0.8790\n",
      "median time per epoch: 0.0154s\n",
      "constructing the metric backbone graph\n",
      "done in 0.5136s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 11217.0, with K = 30 --------------------------\n",
      "Epoch: 001, Loss: 2.3513, Train: 0.2370, Test: 0.2300\n",
      "Epoch: 010, Loss: 1.1283, Train: 0.7580, Test: 0.7140\n",
      "Epoch: 020, Loss: 0.7160, Train: 0.8390, Test: 0.7720\n",
      "Epoch: 030, Loss: 0.5759, Train: 0.8740, Test: 0.7950\n",
      "Epoch: 040, Loss: 0.4808, Train: 0.8810, Test: 0.8180\n",
      "Epoch: 050, Loss: 0.4408, Train: 0.8920, Test: 0.8350\n",
      "Epoch: 060, Loss: 0.4196, Train: 0.9030, Test: 0.8440\n",
      "Epoch: 070, Loss: 0.4435, Train: 0.9130, Test: 0.8470\n",
      "Epoch: 080, Loss: 0.3778, Train: 0.9180, Test: 0.8490\n",
      "Epoch: 090, Loss: 0.3843, Train: 0.9230, Test: 0.8510\n",
      "Epoch: 100, Loss: 0.3622, Train: 0.9240, Test: 0.8520\n",
      "median time per epoch: 0.0157s\n",
      "constructing the metric backbone graph\n",
      "done in 0.6500s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 12130.0, with K = 40 --------------------------\n",
      "Epoch: 001, Loss: 2.3270, Train: 0.1280, Test: 0.1280\n",
      "Epoch: 010, Loss: 1.4579, Train: 0.6210, Test: 0.6070\n",
      "Epoch: 020, Loss: 1.0049, Train: 0.7110, Test: 0.7240\n",
      "Epoch: 030, Loss: 0.8359, Train: 0.7810, Test: 0.8020\n",
      "Epoch: 040, Loss: 0.7465, Train: 0.8260, Test: 0.8380\n",
      "Epoch: 050, Loss: 0.6501, Train: 0.8510, Test: 0.8470\n",
      "Epoch: 060, Loss: 0.6277, Train: 0.8560, Test: 0.8530\n",
      "Epoch: 070, Loss: 0.5928, Train: 0.8710, Test: 0.8590\n",
      "Epoch: 080, Loss: 0.5665, Train: 0.8740, Test: 0.8630\n",
      "Epoch: 090, Loss: 0.5355, Train: 0.8790, Test: 0.8680\n",
      "Epoch: 100, Loss: 0.5001, Train: 0.8810, Test: 0.8740\n",
      "median time per epoch: 0.0161s\n",
      "constructing the metric backbone graph\n",
      "done in 0.7658s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 12982.0, with K = 50 --------------------------\n",
      "Epoch: 001, Loss: 2.3447, Train: 0.1200, Test: 0.1120\n",
      "Epoch: 010, Loss: 1.1173, Train: 0.6970, Test: 0.7020\n",
      "Epoch: 020, Loss: 0.7267, Train: 0.7950, Test: 0.7610\n",
      "Epoch: 030, Loss: 0.5944, Train: 0.8390, Test: 0.8030\n",
      "Epoch: 040, Loss: 0.5552, Train: 0.8530, Test: 0.8200\n",
      "Epoch: 050, Loss: 0.4819, Train: 0.8830, Test: 0.8440\n",
      "Epoch: 060, Loss: 0.4778, Train: 0.8880, Test: 0.8450\n",
      "Epoch: 070, Loss: 0.4236, Train: 0.8940, Test: 0.8600\n",
      "Epoch: 080, Loss: 0.4317, Train: 0.8980, Test: 0.8670\n",
      "Epoch: 090, Loss: 0.4278, Train: 0.9010, Test: 0.8660\n",
      "Epoch: 100, Loss: 0.3846, Train: 0.9070, Test: 0.8660\n",
      "median time per epoch: 0.0167s\n",
      "constructing the metric backbone graph\n",
      "done in 1.0000s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 13795.0, with K = 60 --------------------------\n",
      "Epoch: 001, Loss: 2.3868, Train: 0.2030, Test: 0.2450\n",
      "Epoch: 010, Loss: 1.2236, Train: 0.6300, Test: 0.6220\n",
      "Epoch: 020, Loss: 0.8350, Train: 0.7550, Test: 0.7360\n",
      "Epoch: 030, Loss: 0.7000, Train: 0.8070, Test: 0.7900\n",
      "Epoch: 040, Loss: 0.5834, Train: 0.8450, Test: 0.8240\n",
      "Epoch: 050, Loss: 0.5392, Train: 0.8630, Test: 0.8570\n",
      "Epoch: 060, Loss: 0.4730, Train: 0.8810, Test: 0.8650\n",
      "Epoch: 070, Loss: 0.4835, Train: 0.8860, Test: 0.8690\n",
      "Epoch: 080, Loss: 0.4417, Train: 0.8930, Test: 0.8680\n",
      "Epoch: 090, Loss: 0.3966, Train: 0.8940, Test: 0.8650\n",
      "Epoch: 100, Loss: 0.3886, Train: 0.8970, Test: 0.8710\n",
      "median time per epoch: 0.0174s\n",
      "constructing the metric backbone graph\n",
      "done in 1.0308s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 14511.0, with K = 70 --------------------------\n",
      "Epoch: 001, Loss: 2.2631, Train: 0.2790, Test: 0.2600\n",
      "Epoch: 010, Loss: 1.1040, Train: 0.7480, Test: 0.6820\n",
      "Epoch: 020, Loss: 0.7270, Train: 0.8180, Test: 0.7480\n",
      "Epoch: 030, Loss: 0.5925, Train: 0.8530, Test: 0.7830\n",
      "Epoch: 040, Loss: 0.5218, Train: 0.8560, Test: 0.8020\n",
      "Epoch: 050, Loss: 0.4831, Train: 0.8730, Test: 0.8220\n",
      "Epoch: 060, Loss: 0.4554, Train: 0.8800, Test: 0.8260\n",
      "Epoch: 070, Loss: 0.4222, Train: 0.8930, Test: 0.8250\n",
      "Epoch: 080, Loss: 0.4032, Train: 0.9040, Test: 0.8390\n",
      "Epoch: 090, Loss: 0.3908, Train: 0.9150, Test: 0.8430\n",
      "Epoch: 100, Loss: 0.3954, Train: 0.9070, Test: 0.8360\n",
      "median time per epoch: 0.0177s\n",
      "constructing the metric backbone graph\n",
      "done in 1.3047s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 15119.0, with K = 80 --------------------------\n",
      "Epoch: 001, Loss: 2.3674, Train: 0.1640, Test: 0.1620\n",
      "Epoch: 010, Loss: 1.5846, Train: 0.5420, Test: 0.5750\n",
      "Epoch: 020, Loss: 1.0417, Train: 0.7220, Test: 0.7390\n",
      "Epoch: 030, Loss: 0.8472, Train: 0.7760, Test: 0.7900\n",
      "Epoch: 040, Loss: 0.7039, Train: 0.8150, Test: 0.8270\n",
      "Epoch: 050, Loss: 0.6616, Train: 0.8270, Test: 0.8390\n",
      "Epoch: 060, Loss: 0.5787, Train: 0.8480, Test: 0.8540\n",
      "Epoch: 070, Loss: 0.5240, Train: 0.8670, Test: 0.8620\n",
      "Epoch: 080, Loss: 0.5202, Train: 0.8780, Test: 0.8680\n",
      "Epoch: 090, Loss: 0.4850, Train: 0.8750, Test: 0.8620\n",
      "Epoch: 100, Loss: 0.4534, Train: 0.8850, Test: 0.8720\n",
      "median time per epoch: 0.0179s\n",
      "constructing the metric backbone graph\n",
      "done in 1.6312s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 15769.0, with K = 90 --------------------------\n",
      "Epoch: 001, Loss: 2.3342, Train: 0.2940, Test: 0.2950\n",
      "Epoch: 010, Loss: 1.0637, Train: 0.7110, Test: 0.6600\n",
      "Epoch: 020, Loss: 0.7217, Train: 0.7860, Test: 0.7780\n",
      "Epoch: 030, Loss: 0.6049, Train: 0.8400, Test: 0.8030\n",
      "Epoch: 040, Loss: 0.5079, Train: 0.8740, Test: 0.8300\n",
      "Epoch: 050, Loss: 0.4649, Train: 0.8870, Test: 0.8540\n",
      "Epoch: 060, Loss: 0.4296, Train: 0.9070, Test: 0.8680\n",
      "Epoch: 070, Loss: 0.4003, Train: 0.9090, Test: 0.8660\n",
      "Epoch: 080, Loss: 0.3831, Train: 0.9230, Test: 0.8690\n",
      "Epoch: 090, Loss: 0.3811, Train: 0.9150, Test: 0.8690\n",
      "Epoch: 100, Loss: 0.3689, Train: 0.9240, Test: 0.8710\n",
      "median time per epoch: 0.0185s\n",
      "constructing the metric backbone graph\n",
      "done in 1.6981s\n",
      "-------------------------- Running the model Metric Backbone sparsified |E| = 16315.0, with K = 100 --------------------------\n",
      "Epoch: 001, Loss: 2.3636, Train: 0.1480, Test: 0.1320\n",
      "Epoch: 010, Loss: 1.3443, Train: 0.6600, Test: 0.6850\n",
      "Epoch: 020, Loss: 0.8412, Train: 0.7760, Test: 0.7660\n",
      "Epoch: 030, Loss: 0.6532, Train: 0.8310, Test: 0.8110\n",
      "Epoch: 040, Loss: 0.5631, Train: 0.8520, Test: 0.8250\n",
      "Epoch: 050, Loss: 0.5328, Train: 0.8630, Test: 0.8380\n",
      "Epoch: 060, Loss: 0.4792, Train: 0.8860, Test: 0.8400\n",
      "Epoch: 070, Loss: 0.4658, Train: 0.8850, Test: 0.8430\n",
      "Epoch: 080, Loss: 0.4437, Train: 0.8940, Test: 0.8510\n",
      "Epoch: 090, Loss: 0.4467, Train: 0.9020, Test: 0.8530\n",
      "Epoch: 100, Loss: 0.4138, Train: 0.9070, Test: 0.8520\n",
      "median time per epoch: 0.0188s\n"
     ]
    }
   ],
   "source": [
    "for k_idx, k in enumerate(K_range):\n",
    "    knn_weight_matrix = gl.weightmatrix.knn(source_data, k=k)\n",
    "    print(f\"constructing the metric backbone graph\")\n",
    "    start_mb_sparsify = time.time()\n",
    "    mb_sparse_knn_weight_matrix = mb_sparsify(np.nan_to_num((1/knn_weight_matrix.todense())-1, posinf = 0, neginf = 0))\n",
    "    mb_sparsify_time = time.time() - start_mb_sparsify\n",
    "    print(f\"done in {mb_sparsify_time:.4f}s\")\n",
    "    mb_sparsification_time[k_idx] = mb_sparsify_time\n",
    "    mb_num_edges[k_idx] = get_num_edges_from_adj_matrix(mb_sparse_knn_weight_matrix)\n",
    "    train_mask, test_mask = generate_train_and_test_mask(N) \n",
    "    \n",
    "    print(f'-------------------------- Running the model Metric Backbone sparsified |E| = {mb_num_edges[k_idx]}, with K = {k} --------------------------')\n",
    "    # Running the model on the metric backbone sparsified graph\n",
    "    mb_x = torch.tensor(source_data, dtype=torch.float)\n",
    "    mb_y = torch.tensor(labels, dtype=torch.long)\n",
    "    mb_edge_index = (\n",
    "        torch.tensor(mb_sparse_knn_weight_matrix).nonzero().t().contiguous()\n",
    "    )\n",
    "    mb_data = Data(x=mb_x, edge_index=mb_edge_index, y=mb_y).to(device)\n",
    "    # NOTE: des num_nodes update after having cut the dataset to get the subsample ?\n",
    "    mb_model = GCN(num_features, 16, num_classes).to(device)\n",
    "    \n",
    "    mb_optimizer = torch.optim.Adam([\n",
    "        dict(params=mb_model.conv1.parameters(), weight_decay=5e-4),\n",
    "        dict(params=mb_model.conv2.parameters(), weight_decay=0)\n",
    "    ], lr=0.01)  # Only perform weight-decay on first convolution.\n",
    "    \n",
    "    best_val_acc, accs, median_time_per_epoch, overall_time = eval_model(mb_model, \n",
    "                                                                            mb_data,\n",
    "                                                                            train_mask,\n",
    "                                                                            test_mask, \n",
    "                                                                            mb_optimizer,\n",
    "                                                                            N_EPOCHS)\n",
    "    \n",
    "    print(f\"median time per epoch: {median_time_per_epoch:.4f}s\")\n",
    "    mb_best_accuracies[k_idx] = best_val_acc\n",
    "    mb_accuracies[k_idx] = accs\n",
    "    mb_graph_training_time_per_epoch[k_idx] = median_time_per_epoch\n",
    "    mb_training_time[k_idx] = overall_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 1999, 1999, 1999], dtype=int32),\n",
       " array([  13,   40,   61, ..., 1982, 1983, 1988], dtype=int32))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_weight_matrix.nonzero()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Sparsified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats for the threshold\n",
    "thresh_training_time = np.zeros(len(K_range))\n",
    "thresh_graph_training_time_per_epoch = np.zeros(len(K_range))\n",
    "thresh_accuracies = np.zeros(((len(K_range), N_EPOCHS)))\n",
    "thresh_best_accuracies = np.zeros(len(K_range))\n",
    "thresh_num_edges = np.zeros(len(K_range))\n",
    "thresh_sparsification_time = np.zeros(len(K_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing the threshold graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/t1p1zlw56kx34l_phf3ncrg40000gn/T/ipykernel_22586/499155617.py:5: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist_matrix = mb_sparsify(np.nan_to_num((1/knn_weight_matrix.todense())-1, posinf = 0, neginf = 0, nan = 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.3430s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 7514.0, with K = 10 --------------------------\n",
      "Epoch: 001, Loss: 2.2838, Train: 0.2410, Test: 0.2310\n",
      "Epoch: 010, Loss: 1.1800, Train: 0.7170, Test: 0.6720\n",
      "Epoch: 020, Loss: 0.7521, Train: 0.8460, Test: 0.8300\n",
      "Epoch: 030, Loss: 0.5916, Train: 0.8720, Test: 0.8540\n",
      "Epoch: 040, Loss: 0.5235, Train: 0.8950, Test: 0.8570\n",
      "Epoch: 050, Loss: 0.4862, Train: 0.9010, Test: 0.8570\n",
      "Epoch: 060, Loss: 0.4539, Train: 0.9070, Test: 0.8650\n",
      "Epoch: 070, Loss: 0.4364, Train: 0.9180, Test: 0.8710\n",
      "Epoch: 080, Loss: 0.3854, Train: 0.9200, Test: 0.8770\n",
      "Epoch: 090, Loss: 0.3660, Train: 0.9270, Test: 0.8740\n",
      "Epoch: 100, Loss: 0.3970, Train: 0.9200, Test: 0.8710\n",
      "constructing the threshold graph\n",
      "done in 0.4493s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 9903.0, with K = 20 --------------------------\n",
      "Epoch: 001, Loss: 2.4213, Train: 0.3050, Test: 0.3130\n",
      "Epoch: 010, Loss: 1.3698, Train: 0.6330, Test: 0.6340\n",
      "Epoch: 020, Loss: 0.8795, Train: 0.8110, Test: 0.7990\n",
      "Epoch: 030, Loss: 0.6811, Train: 0.8520, Test: 0.8330\n",
      "Epoch: 040, Loss: 0.5681, Train: 0.8690, Test: 0.8480\n",
      "Epoch: 050, Loss: 0.5165, Train: 0.8810, Test: 0.8560\n",
      "Epoch: 060, Loss: 0.4819, Train: 0.8910, Test: 0.8680\n",
      "Epoch: 070, Loss: 0.4695, Train: 0.8940, Test: 0.8730\n",
      "Epoch: 080, Loss: 0.4709, Train: 0.9050, Test: 0.8710\n",
      "Epoch: 090, Loss: 0.4410, Train: 0.9100, Test: 0.8740\n",
      "Epoch: 100, Loss: 0.4403, Train: 0.9180, Test: 0.8730\n",
      "constructing the threshold graph\n",
      "done in 0.7613s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 11217.0, with K = 30 --------------------------\n",
      "Epoch: 001, Loss: 2.4055, Train: 0.2460, Test: 0.2790\n",
      "Epoch: 010, Loss: 1.2751, Train: 0.6660, Test: 0.6750\n",
      "Epoch: 020, Loss: 0.8372, Train: 0.7940, Test: 0.7850\n",
      "Epoch: 030, Loss: 0.6579, Train: 0.8210, Test: 0.8070\n",
      "Epoch: 040, Loss: 0.5735, Train: 0.8700, Test: 0.8410\n",
      "Epoch: 050, Loss: 0.5466, Train: 0.8860, Test: 0.8530\n",
      "Epoch: 060, Loss: 0.4898, Train: 0.8930, Test: 0.8610\n",
      "Epoch: 070, Loss: 0.4504, Train: 0.9070, Test: 0.8640\n",
      "Epoch: 080, Loss: 0.4551, Train: 0.9110, Test: 0.8600\n",
      "Epoch: 090, Loss: 0.4435, Train: 0.9120, Test: 0.8680\n",
      "Epoch: 100, Loss: 0.4271, Train: 0.9230, Test: 0.8700\n",
      "constructing the threshold graph\n",
      "done in 1.0029s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 12130.0, with K = 40 --------------------------\n",
      "Epoch: 001, Loss: 2.4223, Train: 0.3280, Test: 0.3390\n",
      "Epoch: 010, Loss: 1.2606, Train: 0.6450, Test: 0.6340\n",
      "Epoch: 020, Loss: 0.8082, Train: 0.7850, Test: 0.7610\n",
      "Epoch: 030, Loss: 0.6583, Train: 0.8360, Test: 0.8130\n",
      "Epoch: 040, Loss: 0.6027, Train: 0.8600, Test: 0.8300\n",
      "Epoch: 050, Loss: 0.5301, Train: 0.8680, Test: 0.8350\n",
      "Epoch: 060, Loss: 0.4785, Train: 0.8850, Test: 0.8550\n",
      "Epoch: 070, Loss: 0.4884, Train: 0.8910, Test: 0.8630\n",
      "Epoch: 080, Loss: 0.4690, Train: 0.9020, Test: 0.8670\n",
      "Epoch: 090, Loss: 0.4389, Train: 0.9060, Test: 0.8530\n",
      "Epoch: 100, Loss: 0.4361, Train: 0.9100, Test: 0.8780\n",
      "constructing the threshold graph\n",
      "done in 1.1946s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 12982.0, with K = 50 --------------------------\n",
      "Epoch: 001, Loss: 2.3116, Train: 0.2860, Test: 0.2340\n",
      "Epoch: 010, Loss: 1.1512, Train: 0.7000, Test: 0.7030\n",
      "Epoch: 020, Loss: 0.7593, Train: 0.8020, Test: 0.8050\n",
      "Epoch: 030, Loss: 0.5687, Train: 0.8640, Test: 0.8260\n",
      "Epoch: 040, Loss: 0.5027, Train: 0.8920, Test: 0.8480\n",
      "Epoch: 050, Loss: 0.4870, Train: 0.9060, Test: 0.8570\n",
      "Epoch: 060, Loss: 0.4509, Train: 0.9070, Test: 0.8620\n",
      "Epoch: 070, Loss: 0.4100, Train: 0.8990, Test: 0.8580\n",
      "Epoch: 080, Loss: 0.4086, Train: 0.9120, Test: 0.8750\n",
      "Epoch: 090, Loss: 0.3866, Train: 0.9140, Test: 0.8700\n",
      "Epoch: 100, Loss: 0.3793, Train: 0.9200, Test: 0.8680\n",
      "constructing the threshold graph\n",
      "done in 1.3266s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 13795.0, with K = 60 --------------------------\n",
      "Epoch: 001, Loss: 2.3150, Train: 0.2090, Test: 0.2090\n",
      "Epoch: 010, Loss: 1.1055, Train: 0.7100, Test: 0.7240\n",
      "Epoch: 020, Loss: 0.7930, Train: 0.7820, Test: 0.7750\n",
      "Epoch: 030, Loss: 0.6242, Train: 0.8240, Test: 0.8010\n",
      "Epoch: 040, Loss: 0.5593, Train: 0.8560, Test: 0.8180\n",
      "Epoch: 050, Loss: 0.5221, Train: 0.8640, Test: 0.8310\n",
      "Epoch: 060, Loss: 0.5043, Train: 0.8910, Test: 0.8540\n",
      "Epoch: 070, Loss: 0.4536, Train: 0.8970, Test: 0.8620\n",
      "Epoch: 080, Loss: 0.4218, Train: 0.8940, Test: 0.8700\n",
      "Epoch: 090, Loss: 0.3936, Train: 0.9130, Test: 0.8660\n",
      "Epoch: 100, Loss: 0.3935, Train: 0.9170, Test: 0.8700\n",
      "constructing the threshold graph\n",
      "done in 1.6817s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 14511.0, with K = 70 --------------------------\n",
      "Epoch: 001, Loss: 2.3633, Train: 0.1770, Test: 0.1690\n",
      "Epoch: 010, Loss: 1.5869, Train: 0.4610, Test: 0.4900\n",
      "Epoch: 020, Loss: 1.1558, Train: 0.6890, Test: 0.7010\n",
      "Epoch: 030, Loss: 0.8181, Train: 0.8110, Test: 0.8030\n",
      "Epoch: 040, Loss: 0.6329, Train: 0.8390, Test: 0.8180\n",
      "Epoch: 050, Loss: 0.6013, Train: 0.8680, Test: 0.8490\n",
      "Epoch: 060, Loss: 0.5426, Train: 0.8830, Test: 0.8510\n",
      "Epoch: 070, Loss: 0.5054, Train: 0.8910, Test: 0.8500\n",
      "Epoch: 080, Loss: 0.4689, Train: 0.9020, Test: 0.8610\n",
      "Epoch: 090, Loss: 0.4483, Train: 0.9160, Test: 0.8680\n",
      "Epoch: 100, Loss: 0.4257, Train: 0.9160, Test: 0.8710\n",
      "constructing the threshold graph\n",
      "done in 1.5657s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 15119.0, with K = 80 --------------------------\n",
      "Epoch: 001, Loss: 2.3741, Train: 0.1930, Test: 0.1800\n",
      "Epoch: 010, Loss: 1.2597, Train: 0.6200, Test: 0.6370\n",
      "Epoch: 020, Loss: 0.7743, Train: 0.7880, Test: 0.7840\n",
      "Epoch: 030, Loss: 0.6051, Train: 0.8380, Test: 0.8100\n",
      "Epoch: 040, Loss: 0.5143, Train: 0.8640, Test: 0.8360\n",
      "Epoch: 050, Loss: 0.4894, Train: 0.8830, Test: 0.8440\n",
      "Epoch: 060, Loss: 0.4639, Train: 0.8960, Test: 0.8510\n",
      "Epoch: 070, Loss: 0.4446, Train: 0.9000, Test: 0.8510\n",
      "Epoch: 080, Loss: 0.4207, Train: 0.9060, Test: 0.8590\n",
      "Epoch: 090, Loss: 0.4266, Train: 0.9030, Test: 0.8570\n",
      "Epoch: 100, Loss: 0.4056, Train: 0.9110, Test: 0.8570\n",
      "constructing the threshold graph\n",
      "done in 1.7939s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 15769.0, with K = 90 --------------------------\n",
      "Epoch: 001, Loss: 2.3512, Train: 0.1740, Test: 0.1820\n",
      "Epoch: 010, Loss: 1.3966, Train: 0.5880, Test: 0.5800\n",
      "Epoch: 020, Loss: 0.8958, Train: 0.7500, Test: 0.7560\n",
      "Epoch: 030, Loss: 0.7131, Train: 0.8060, Test: 0.8000\n",
      "Epoch: 040, Loss: 0.6102, Train: 0.8470, Test: 0.8290\n",
      "Epoch: 050, Loss: 0.5280, Train: 0.8650, Test: 0.8410\n",
      "Epoch: 060, Loss: 0.5277, Train: 0.8720, Test: 0.8450\n",
      "Epoch: 070, Loss: 0.5000, Train: 0.8840, Test: 0.8530\n",
      "Epoch: 080, Loss: 0.4490, Train: 0.8960, Test: 0.8590\n",
      "Epoch: 090, Loss: 0.4585, Train: 0.8940, Test: 0.8630\n",
      "Epoch: 100, Loss: 0.4552, Train: 0.9030, Test: 0.8590\n",
      "constructing the threshold graph\n",
      "done in 2.1311s\n",
      "-------------------------- Running the model Threshold sparsified |E| = 16315.0, with K = 100 --------------------------\n",
      "Epoch: 001, Loss: 2.3245, Train: 0.2340, Test: 0.2690\n",
      "Epoch: 010, Loss: 1.1418, Train: 0.6910, Test: 0.7130\n",
      "Epoch: 020, Loss: 0.7956, Train: 0.7930, Test: 0.7900\n",
      "Epoch: 030, Loss: 0.6286, Train: 0.8350, Test: 0.8160\n",
      "Epoch: 040, Loss: 0.5535, Train: 0.8620, Test: 0.8410\n",
      "Epoch: 050, Loss: 0.5052, Train: 0.8870, Test: 0.8500\n",
      "Epoch: 060, Loss: 0.4582, Train: 0.8880, Test: 0.8560\n",
      "Epoch: 070, Loss: 0.4396, Train: 0.9020, Test: 0.8600\n",
      "Epoch: 080, Loss: 0.4445, Train: 0.9020, Test: 0.8670\n",
      "Epoch: 090, Loss: 0.4016, Train: 0.9060, Test: 0.8650\n",
      "Epoch: 100, Loss: 0.4391, Train: 0.9110, Test: 0.8740\n"
     ]
    }
   ],
   "source": [
    "for k_idx, k in enumerate(K_range):\n",
    "    knn_weight_matrix = gl.weightmatrix.knn(source_data, k=k)\n",
    "    print(f\"constructing the threshold graph\")\n",
    "    start_thresh_sparsify = time.time()\n",
    "    dist_matrix = mb_sparsify(np.nan_to_num((1/knn_weight_matrix.todense())-1, posinf = 0, neginf = 0, nan = 0))\n",
    "    thresh_sparse_knn_weight_matrix = thresh_sparsify(dist_matrix, mb_num_edges[k_idx])\n",
    "    thresh_sparsify_time = time.time() - start_thresh_sparsify\n",
    "    print(f\"done in {thresh_sparsify_time:.4f}s\")\n",
    "    thresh_sparsification_time[k_idx] = thresh_sparsify_time\n",
    "    thresh_num_edges[k_idx] = get_num_edges_from_adj_matrix(thresh_sparse_knn_weight_matrix)\n",
    "    \n",
    "    print(f'-------------------------- Running the model Threshold sparsified |E| = {thresh_num_edges[k_idx]}, with K = {k} --------------------------')\n",
    "    # Running the model on the threshold sparsified graph\n",
    "    thresh_x = torch.tensor(source_data, dtype=torch.float)\n",
    "    thresh_y = torch.tensor(labels, dtype=torch.long)\n",
    "    thresh_edge_index = (\n",
    "        torch.tensor(thresh_sparse_knn_weight_matrix).nonzero().t().contiguous()\n",
    "    )\n",
    "    thresh_data = Data(x=thresh_x, edge_index=thresh_edge_index, y=thresh_y).to(device)\n",
    "    # NOTE: des num_nodes update after having cut the dataset to get the subsample ?\n",
    "    thresh_model = GCN(num_features, 16, num_classes).to(device)\n",
    "    \n",
    "    thresh_optimizer = torch.optim.Adam([\n",
    "        dict(params=thresh_model.conv1.parameters(), weight_decay=5e-4),\n",
    "        dict(params=thresh_model.conv2.parameters(), weight_decay=0)\n",
    "    ], lr=0.01)  # Only perform weight-decay on first convolution.\n",
    "    \n",
    "    best_val_acc, accs, median_time_per_epoch, overall_time = eval_model(thresh_model, \n",
    "                                                                            thresh_data,\n",
    "                                                                            train_mask,\n",
    "                                                                            test_mask, \n",
    "                                                                            thresh_optimizer,\n",
    "                                                                            N_EPOCHS)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
